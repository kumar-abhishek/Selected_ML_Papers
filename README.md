# Selected Machine Learning Papers
[![Badge](https://img.shields.io/badge/link-996.icu-%23FF4D5B.svg?style=flat-square)](https://996.icu/#/en_US)

This is a collection of selected machine learning papers I read as a data scientist. The collections mainly includes papers of influential machine learning approaches which may be beyond the scope of machine learning courses or may not appear in machine learning textbook. 

Please feel free to comment and provide suggestions. 

The list is for study purpose only. If any author does not want the paper be listed, please contact xiangshen@gwu.edu. 


***

### Table of Content
* [Classic Machine Learning](https://github.com/sx910604/Selected_ML_Papers#Classic-Machine-Learning)
* [Deep Learning](https://github.com/sx910604/Selected_ML_Papers#Deep-Learning)
* [Recommender System](https://github.com/sx910604/Selected_ML_Papers#Recommender-System)
* [Natural Language Processing](https://github.com/sx910604/Selected_ML_Papers#NLP)
* [Computer Vision](https://github.com/sx910604/Selected_ML_Papers#CV)
* [Reinforcement Learning](https://github.com/sx910604/Selected_ML_Papers#RL)
* [Blogs](https://github.com/sx910604/Selected_ML_Papers#Blogs)

***

### Classic Machine Learning
* **LightGBM** Ke, Guolin, et al. "Lightgbm: A highly efficient gradient boosting decision tree." Advances in neural information processing systems 30 (2017): 3146-3154.
* **Xgboost** Chen, Tianqi, and Carlos Guestrin. "Xgboost: A scalable tree boosting system." Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. 2016.
* **SMOTE** Chawla, Nitesh V., et al. "SMOTE: synthetic minority over-sampling technique." Journal of artificial intelligence research 16 (2002): 321-357.
* **Bayesian Optimization** Snoek, Jasper, Hugo Larochelle, and Ryan P. Adams. "Practical bayesian optimization of machine learning algorithms." Advances in neural information processing systems. 2012.
* **t-SNE** Van der Maaten, L., & Hinton, G. (2008). Visualizing data using t-SNE. Journal of machine learning research, 9(11).
* **Shap** Lundberg, S. M., Erion, G. G., & Lee, S. I. (2018). Consistent individualized feature attribution for tree ensembles. arXiv preprint arXiv:1802.03888.
* **LIME** Ribeiro, M. T., Singh, S., & Guestrin, C. (2016, August). " Why should i trust you?" Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining (pp. 1135-1144).
***

### Deep Learning
* Chawla, Nitesh V., et al. "SMOTE: synthetic minority over-sampling technique." Journal of artificial intelligence research 16 (2002): 321-357.


***

### Recommender System
* Rendle, Steffen. "Factorization machines." 2010 IEEE International Conference on Data Mining. IEEE, 2010.

***

### Natural Language Processing


***

### Computer Vision


***

### Reinforcement Learning


***

### Blogs
* Expedia Group Tech Blog https://medium.com/expedia-group-tech
* Bookings Tech Blog https://blog.booking.com/
* Ctrip Tech https://zhuanlan.zhihu.com/ctriptech Â (Chinese)
* Amazon Science Blog https://www.amazon.science/blog
* AWS Machine Learning https://aws.amazon.com/blogs/machine-learning/
* Facebook AI Blog https://ai.facebook.com/blog
* Google AI Blog https://ai.googleblog.com/
* OpenAI Blog https://openai.com/blog/
* Netflex Tech Blog https://netflixtechblog.com/
* Uber Engineering Blog https://eng.uber.com/
* Lyft Engineering Blog https://eng.lyft.com/
* Quore Engineering Blog https://www.quora.com/q/quoraengineering
* Airbnb Engineering and Data Science Blog https://medium.com/airbnb-engineering/tagged/data-science
* DeepMind Blog https://deepmind.com/blog
* Pinterest Engineering Blog https://medium.com/pinterest-engineering/machine-learning/home
* Linkedin Engineering Blog https://engineering.linkedin.com/blog
* CMU ML Blog https://blog.ml.cmu.edu/
* BAIR Blog https://bair.berkeley.edu/blog/
* Stanford AI Lab Blog http://ai.stanford.edu/blog/
* Meituan Tech https://tech.meituan.com/ (Chinese)

***
